import requests

def ask_ollama(prompt):
    response = requests.post(
        "http://localhost:11434/api/generate",
        json={
            "model": "mistral",
            "prompt": f"""
ë‹¤ìŒ ë¬¸ì¥ì„ light_on / light_off / unknown ì¤‘ í•˜ë‚˜ë¡œë§Œ ë³€í™˜í•´ì¤˜.
- "ë¶ˆ ì¼œ" â†’ light_on
- "ì¡°ëª… ì¼œì¤˜" â†’ light_on
- "ë¶ˆ êº¼ì¤˜" â†’ light_off
- "ì¡°ëª… êº¼" â†’ light_off
- "turn the light on" â†’ light_on
- "light off please" â†’ light_off
- "ì„ í’ê¸° êº¼" â†’ unknown
- "ì—ì–´ì»¨ ì¼œ" â†’ unknown

ë¬¸ì¥: "{prompt}"
ì •ë‹µ:""",
            "stream": False
        }
    )
    return response.json()["response"].strip()

def send_to_raspberry(cmd):
    pi_url = "http://10.10.15.195:5000/light"  # â† ì—¬ê¸° IP ìˆ˜ì •!
    try:
        res = requests.post(pi_url, json={"cmd": cmd})
        print("ğŸ“¡ Pi ì‘ë‹µ:", res.text)
    except Exception as e:
        print("âŒ ì „ì†¡ ì‹¤íŒ¨:", e)

# ë©”ì¸ ë£¨í”„
while True:
    user_input = input("ëª…ë ¹ ì…ë ¥ (exit ì…ë ¥ ì‹œ ì¢…ë£Œ): ")
    if user_input.lower() == "exit":
        break

    cmd = ask_ollama(user_input)
    print("ğŸ“¥ LLM ì‘ë‹µ:", cmd)

    if cmd in ["light_on", "light_off"]:
        send_to_raspberry(cmd)
    else:
        print("âš ï¸ ì‹¤í–‰í•  ëª…ë ¹ì´ ì•„ë‹˜ (unknown)")

